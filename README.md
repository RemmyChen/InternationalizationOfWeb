# InternationalizationOfWeb

Tufts COMP 117 Spring 2019 Final Paper: Internationalization of the Web Today

Introduction
The World Wide Web was invented in 1989 by Tim Berners-Lee, who wrote the first Web browser, Web server, and Web page, as well as the first specifications for HTML, HTTP, and URIs.1, 2 The Web and its technologies are tools that billions of people all over the world use as a central infrastructure for information.3 The prevalence of the Web today is closely tied to the spread of the Web across geographical and national borders and its usage as an international system, highlighting the importance of internationalization in enabling the Web to live up to its World Wide quality. This paper will explore how Web technologies including HTML, HTTP, URIs and other tools meet or don't meet the requirements for people around the world to use the Web.

Background: What is the Web and What is Internationalization?
The World Wide Web (WWW), or commonly referred to as the Web, is defined in W3C's "Architecture of the World Wide Web, Volume I" as "an information space" of "items of interest, referred to as resources".4 The Web is comprised of technologies including HTML, HTTP, URIs, clients and servers. The Web technologies, which are pertinent to the realization of Tim Berner-Lees' dream "of a common information space in which we communicate by sharing information" and relevant to the dicussion in the rest of the paper, are defined as follows.5

HTML, which stands for HyperText Markup Language, is the publishing language of the Web.6 HTML describes the structure of a Web page semantically and allows graphical clients such as browsers to render a document into multimedia a Web page.6 It uses markup tags such as headings, paragraphs, links, and other items written using ASCII characters to compose HTML documents. The first version of HTML was described by Tim Berners-Lee in 1991.6

HTTP, which stands for Hypertext Transfer Protocol, is "an application-level protocol for distributed, collaborative, hypermedia information systems".7 It facilitates data transfer for the World Wide Web by functioning as an text-based, ASCII-encoded, idempotent (stateless) request–response protocol in the client–server computing model.8 In other words, HTTP is what allows Web clients to send requests to Web servers and Web servers to send responses to Web clients. In the first version of HTTP (HTTP/0.9), HTTP only had one request method (GET), which would request a page from a server, but it has since then evolved to include a variety of request methods.9 The response from the server is an HTML page, represented by a byte stream of ASCII characters.9

URI, which stands for Uniform Resource Identifier, is a sequence of characters that unambigiously identifies a particular resource, such as a document, an image, or a downloadable file, over a network such as the Web.10 A URI's permitted characters are the ASCII characters for the lowercase and uppercase letters of the modern English alphabet, the Arabic numerals, period, underscore, hyphen, and tilde.10 Other ASCII characters are percent-encoded, meaning that they are encoded with a percent sign immediately followed by two hexadecimal digits, which represent the ISO Latin 1 code for that character.10 Particularly in the case of white space characters such as a tab, a new line, and a space, percent-encoding is important to avoid confusion and reduce usability. HTTP resources may be identified on the Web by name, address, or context using URI schemes http and https, and may require more than one protocol.10 For example, when a representation isn't found in a local cache, domain name registries may also be used to translate the domain name in the URI into the IP address of a server that is proximal to the user.10 The URI is unique in that, according to the W3C's "Naming and Addressing: URIs, URLs, ...", "unlike web data formats, where HTML is an important one, but not the only one, and web protocols, where HTTP has a similar status, there is only one Web naming/addressing technology: URIs".11

The usage of HTML, HTTP, and URIs in a client-server model of the Web works via requests and responses. To demonstrate, a client would request for a particular resource by URI over HTTP, and a proximal server on which the resource in request is found would respond by sending the resource, encoded in HTML, back to the client over HTTP. In theory, with appropriate hardware infrastructure support and network service, this model should allow the Web to share information across and beyond physical boundaries, allowing for the integration of the world’s information. Indeed, Tim Berners-Lee writes on the Web's 28th anniversary in 2017, "I imagined the Web as an open platform that would allow everyone, everywhere to share information, access opportunities and collaborate across geographic and cultural boundaries".12

The Web as originally envisioned by Tim Berners-Lee upholds two important characteristicss, which are that the Web is universal and international.13 "Universal" and "international" are both semantically descriptive but overly nuanced, because describing something as "universal" is comparable to saying that something "affects all persons or things in the universe", which is a rather human-centric and geocentric if not hyperbolic way of describing a thing, and describing something as "international" is comparable to saying something "exists, occurs or is carried on between two or more nations", which builds on an the semantically overloaded notion of nation-states. So what does it really mean to say that universality and internationalization are essential to the Web?

Universality, as used by Tim Berners-Lee, refers to "the fact that a hypertext link can point to anything, be it personal, local or global, be it draft or highly polished" and is concerned with whether the resources of the Web are linked together.14 Internationalization, on the other hand, refers to the fact that "all kinds of languages [...] can be shared and used on the Web" and is concerned with whether the end users of the Web may gain access albeit language and cultural differences.13 Design aspects relating to the internationalization include data encoding, data transfer, data presentation, and data storage. The Web with regards to internationalization will be the focus of this paper, where internationalization is a mechanism for a product or service to be adapted to various languages, regions, and technical requirements.

Successes of the Web with Regards to Internationalization
The foremost of the various successes of the Web with regards to internationalization is that it is used all over the world today, as Tim Berners-Lee had originally envisioned. The prevalence of the Web in itself may be regarded as an achievement because as American singer David Allen Coe once said, "It is not the beauty of a building you should look at; it is the construction of the foundation that will stand the test of time". Where many tools, technologies, and industries have been in one form or another overturned, eliminated or replaced in the past three decades perhaps in some part due to the usage of the Web, the Web is existent and in usage on massive scale. To remain deeply rooted in the stream of time, from the past to the present to the future, is itself a considerable feat in the face of a multitude of unforeseeable factors and complications, any of which could have easily capsized the Web. How has the Web met the demands of people around the world up to this point, across time and space around the world and among various cultures and politicial ideologies, whose disagreements have brought down nations for lesser causes?

An important characteristic of the Web that may relate to the success of the Web with regards to internationalization is its extensibility. While Tim Berners-Lee didn't fully introduce tools that encourage internationalization in earlier versions of Web technologies, it was possible to later add and modify these tools where necessary, including the support of various human languages in data formatting by HTML, the support of various human languages in resource identification by URIs, and the support of various languages in data presentation by Web clients.

An example is the introduction of non-ASCII characters to HTML. When the Web was invented, computer software and hardware had little support for encoding characters outside of ASCII character set, which was invented in in the 1950s.15 Reasons for this limitation included technical limitations of early computer systems (such as memory limitations), a lack of international standards, and the prominence of English-speaking countries in the development and popularization of computer systems. As such, the Web originally provided little support for non-ASCII characters, and it was challenging to represent languages that used characters outside of ASCII character encoding.16 However, beginning with HTML 4.0, which was recommended by W3C in 1999, HTML began to accommodate to the needs of internationalization.17

The ways by which Web technologies were modified to support non-ASCII characters in HTML were multifold. For example, specifications for HTML 4.0 were introduced to allow the language of content to be specified using the lang attribute in any HTML element, to allow the directionality of text to be specified using the dir attribute in any HTML element, and to allow various encoding types, including UTF-8, to be specified using the charset attribute in the meta tag.17 At the same time, Unicode was becoming a popular choice for websites to use, because it allows usage of the same encoding for nearly all languages. The idea for an "international/multilingual text character encoding system [...] tentatively called Unicode" was first proposed in 1988, and in 1991, the year that HTML became in use, the first volume of the Unicode standard was published.18 In 2007, UTF-8 encoding surpassed ASCII as the most common character encoding on the Web, reflecting wide adoption of UTF-8 on the Web.19 A driving force behind the design of UTF-8 is that it is backwards compatible with 7-bit ASCII.20 In UTF-8, the first 128 Unicode code points are ASCII characters, meaning that 7-bit bytes in a UTF-8 stream represent the same sequence of characters under the interpretation of ASCII and UTF-8 and that software programs such as text processors, parsers, text display programs, and so forth may continue to work as intended by treating UTF-8 byte stream as a sequence of single-byte characters and skipping over multi-byte sequences.21 In addition, multi-byte sequences in UTF-8 will never be misinterpreted as 7-bit ASCII characters.21 Altogether, it is therefore unsurprising that in the specifications for HTML 5, which was recommended by W3C in 2014, the default character encoding became UTF-8, which now "covers almost all the characters, punctuations, and symbols in the world [...] and enables the processing, storage, and transport of text independent of platform and language".22, 23 It is equally unsurprising but nonetheless notable that with the tides turned, eventually various companies undertook browser support for the new tags and attributes, vastly improving browsers' services with regards to internationalization.24 Costs associated with supporting a much larger character set include Web servers having to use more storage space for characters with multibyte encodings, Web clients having to adjust the parsing and handling of different character sets and encodings, and content creators having to remember specifications for declaring character sets, encodings, and languages used.

Another example of how the flexibility of the Web technologies allowed for the Web to meet the requirements of internationalization is the introduction of internationalized domain names (IDNs) and Internationalized Resource Identifiers (IRIs). Prior to the standardization and usage of IDNs and IRIs in the early 2000s, URIs, which contain domain names, were originally designed to support only a subset of ASCII characters, the subset being the lowercase and uppercase letters of the modern English alphabet, the Arabic numerals, period, underscore, hyphen, and tilde.10, 25 Reasons for using a small set of characters included that the limited size of the permitted character set would help with URI transcription, sharing, and usability particularly when URIs are moved between contexts, such as if one were to share an URI that contains confusable characters with another by scrawling on paper, or if one were to copy and paste an URI into an online messaging tool that may or may not be able to preserve each character's encoding. For example, the Latin letter "o" and the Greek letter omicron "ο" and the Hebrew character "ס" look confusingly similar in presentation, may look even more similar depending on the font used, and are not guaranteed to be preserved and resolved in the same way in all contexts, whether online or offline.26 However, the difficulties in supporting all characters notwithstanding, there has been a growing need for the representation and usage of characters from any language within a URI directly, for example so that it is "easier to create, memorize, transcribe, interpret, guess, and relate to" especially for those who are not familiar with the modern English character set.27 As such, IDNs and IRIs have been introduced.

The way that IDNs and IRIs currently work starts with a user clicking on an IRI hyperlink in a Web document that already supports non-ASCII encodings, such as HTML 4.0 or above, or entering an IRI in the address bar of a user agent that supports IDNs and IRIs, including Internet Explorer 7, Firefox, Mozilla, Netscape, Opera, and Safari.27 HTTP and other protocols generally only support ASCII encodings, so the IRI must be converted into ASCII encoding by the user agent if it is not in ASCII.27 For domain names, if the domain name is not in Unicode, the user agent converts the string to Unicode; then the user agent normalizes the string, such as by converting uppercase characters to lowercase and by eliminating prohibited characters (i.e. spaces), to eliminate ambiguities; next, the user agent converts each Unicode substring between dots into an ASCII substring using punycode representation.27 The end result is entirely in ASCII such that it will be transmitted by HTTP just like any URI.27 The punycode representation is resolved by the domain name registries just like any other domain name, assuming that registration of the IRI with domain name registries is also in punycode representation.27 For URI paths, the user agent similary converts the string to Unicode if the path is not in Unicode already; then, the user agent normalizes the string and encodes it in UTF-8; next, the user agent converts the non-ASCII characters into ASCII characters using percent-encoding.27 On the server side, if the server exposes the file names in UTF-8, then the server may access resource; otherwise, the server needs to convert the path from UTF-8 to another encoding.27 Costs associated with supporting IDNs and IRIs include Web clients having to support IRIs and do a number of conversions for IRIs to become entirely represented in ASCII, Web servers having to ensure that file names and IRIs are in matching encoding, registrants having to remember to register their IRIs with domain name registries and link IRIs in HTML documents correctly, domain name registries having to offer registration of IRIs, and end users having to be careful about sharing hyperlinks in different contexts, some of which might not be Web-based.

Challenges of the Web with Regards to Internationalization
A U.S. Federal judge once said, in defense of freedom of expression on the Internet, "The Internet is a far more speech-enhancing medium than print, the village green, or the mails.... The Internet may fairly be regarded as a never-ending worldwide conversation".28 However, the conversation is hardly worldwide if only a subset of participants engage in it.29 Looking at Web content as a metric for gauging the Web's internationalization, according to W3Tech's survey, 54.1% of the top 10 million websites on the Web with known content language is in English as of April, 2019, the runner ups being Russian at 6.0% and German at 5.9%.29 A total of 187 languages were listed, with 147 of them used by less than 0.1% of the websites, suggesting that, of the more than 7,000 existing languages in the world, only a subset are in use for Web pages, and only a subset of that are in common use for Web pages. 29, 30 While one may reasonably expect Web content to become more balanced in time, especially with continual introduction of specifications and guidelines for internationalization, what are some of the current challenges that stand in the way of the Web meeting the needs of internationalization?

A challenge may be to support multilingual Web pages. A multilingual website is one that offers content in multiple languages, where content may be presented in a single language at a time or a mixture of multiple languages within the same page.31 Currently, for content creators, there is no good way of managing multilingual Web pages other than manually. For example, when serving a Web page, content may be statically coded in HTML, which means any addition or update has to be manually changed for each supported language, or content may be dynamically loaded, which has costs including that search engines such as Google may not find and crawl all the equivalent pages in different languages, making it difficult for users to find the page with the desired language in the first place.31 The difficulties in managing multilingual Web pages increase the costs of supporting numerous and less popular languages in favor of supporting fewer and more popular languages, forming a classic positive feedback loop where content creators and Web users find advantages in offering and engaging with the Web with more dominant languages, thus reinforcing those languages' popularity and driving new content creators and new Web users into these dominant languages as well. Is the drive for people using less prevalent languages to use more prevalent languages good or not? Proponents may cite a number of advantages centering around the utility that stronger, more well-established languages give to speakers, while opponents may cite a number of disadvantages centering around the eventual disappearance of weaker languages. In any case, this question aside, one must acknolwedge that the feedback loop does the burden of extra work on end users of less prevalent languages to use the Web as end users of more prevalent languages may, posing an obstacle for end users speaking less prevalent languages in their access to Web resources.

Another challenge in meeting the needs of internationalization may be to place more safeguards against cyber attacks on a more unified front when supporting a large repertoire of characters. For example, currently end users who use IDNs and IRIs are more vulnerable to a particular type of phishing attacks called visual spoofing.27 This is an instance of an abstraction leak, where an end user assumes that querying for any IRI will receive an intended resource, but actually different IRIs carry different risks of cyber attacks. Visual spoofing works by using visually confusable strings to trick end users into mistaking one for the other.32 Visual spoofing is a security concern when using ASCII-based URIs, such as "I" being confusable with "l" and "rn" being confusable with "m" in certain fonts, but is even more so when using, for example, Unicode-based IRIs, where characters of different code points may look identical.32 For example, Unicode character U+0430, Cyrillic small letter a, may look identical to Unicode character U+0061, Latin small letter a.32 Mechanisms that are in place to prevent possible spoofing attacks include the usage of normalization and casefolding when processing IRIs by Web clients, normalization meaning conversion of sequences of code points that represent essentially the same character (for example, converting halfwidth Japanese character ｶ to fullwidth character カ) and casefoldng meaning reduction of characters to a lowercase form, which are generally more distinctive than uppercase form.32 Web clients may also have some control over character display and have various mechanisms in place to alert end users of a possible visual spoofing attack, though the degree of sophistication of these mechanisms tend to vary across Web clients.27 Domain name registries also reduce the possibility of attack by providing bundling services to registrants for domain names that are considered distinct to registries but similar end users. For example, to cover variant spellings, registrants may want to register both "analyze.com" and "analyse.com", "resume.com" and "résumé.com", and so forth.32 However, despite the various mechanisms in place to prevent possible cyber attacks, visual spoofing may still occur more easily with IRIs, especially considering that Web clients and domain name registries owned by various, decentralized entities are not all equally and proactively responsive to security issues.32 More critically, there is currently no standard, foolproof way of identifying a spoof IRI from an user-intended IRI. Perhaps a centralized system for phishing reporting may be a future solution to help mitigate this problem, though the reporting will necessarily always fall several steps behind the attacks.

Conclusion
According to Bob Metcalfe's Law of network effects, the value of a network grows with the square of the number of participants.33 In other words, in a distributed network, the greater the number of users using its services, the more valuable the network becomes to the society. The Web is a prime example that illustrates Metcalfe's Law, whereby the more open and accessible it is, the more valuable it is. Internationalization of the Web is a key component that increases the number of Web users and the Web's value, and in this paper various aspects of the Web with regards to its internationalization have been discussed. Further work must be done so that the Web is as accessible to anyone, anywhere as possible.

Acknowledgements
Many thanks to peers in the Internet-Wide Distributed Systems 2019 Spring class for fruitful discussions and to Professor Noah Mendelsohn for leading the insightful philosophical discourses.

This paper has been fun to write and I have learned a lot about the internationalization of the Web from it. Surprisingly, this topic has been fairly difficult to do research on particularly where various parties' stakes and decision rationales are involved, because there are documents scattered across time on this topic but nothing to weave them together into a unifying story of the Web's progression towards internationalization, which I hope that my paper will now shed some light on, if only briefly.

Bibliography
1. "Tim Berners-Lee." W3C, 4 Feb. 2019, https://www.w3.org/People/Berners-Lee/

2. "Help and FAQ." W3C, https://www.w3.org/Help/#webinternet

3. "Web at 25: Sir Tim Berners-Lee's Address at Net Mundial." W3C, 7 May 2014, https://www.w3.org/webat25/news/sir-tim-berners-lees-address-at-net-mundial

4. "Architecture of the World Wide Web, Volume One: W3C Recommendation 15 December 2004." W3C, 15 Dec, 2004 https://www.w3.org/TR/webarch/

5. "The World Wide Web: A Very Short Personal History." W3C, 7 May 1998, https://www.w3.org/People/Berners-Lee/ShortHistory.html

6. "What Is HTML." W3C, https://www.w3.org/wiki/Html/Training/What_is_HTML

7. "HTTP/1.1: Introduction." W3C, https://www.w3.org/Protocols/rfc2616/rfc2616-sec1.html

8. "HyperText Transfer Protocol." W3C, https://www.w3.org/History/19921103-hypertext/hypertext/WWW/Protocols/HTTP.html

9. "The Original HTTP as Defined in 1991." W3C, https://www.w3.org/Protocols/HTTP/AsImplemented.html

10. "Uniform Resource Identifier (URI): Generic Syntax." IETF Tools, https://tools.ietf.org/html/rfc3986

11. "Naming and Addressing: URIs, URLs, ...." W3C, https://www.w3.org/Addressing/

12. “Three Challenges for the Web, According to Its Inventor.” World Wide Web Foundation, https://webfoundation.org/2017/03/web-turns-28-letter/

13. World Wide Web Consortium (W3C) Launches Internationalization Initiative. W3C, https://www.w3.org/2018/07/pressrelease-i18n-initiative.html.en

14. "Frequently Asked Questions by the Press - Tim BL." W3C, https://www.w3.org/People/Berners-Lee/FAQ.html

15. "A Brief History of Character Sets." https://www-user.tu-chemnitz.de/~heha/viewchm.php/hs/petzold.chm/petzoldi/ch02b.htm

16. "HTML Unicode (UTF-8) Reference." W3Schools, https://www.w3schools.com/charsets/ref_html_utf8.asp

17. "HTML 4.01 Specification: W3C Recommendation 24 December 1999, superseded 27 March 2018." W3C, https://www.w3.org/TR/html401/

18. Becker, Joseph D. "Unicode 88." unicode.org, 29 August 1988, https://unicode.org/history/unicode88.pdf

19. Dubost, Karl. "UTF-8 Growth on the Web. W3C," 6 May 2008, https://www.w3.org/blog/2008/05/utf8-web-growth/

20. Riecken, Tom. "ASCII Encoding: Beginners, Newbies....We've Got All Of The Info You Need Here." 16 Feb. 2019, https://www.whoishostingthis.com/resources/ascii/

21. Gross, Chris. "Fixes The Build: Unicode String." Vicarious Visions, 7 Feb. 2019, https://www.vvisions.com/fixes-the-build-unicode-string/

22. "HTML5 Is a W3C Recommendation." W3C, 28 Oct. 2014, https://www.w3.org/blog/news/archives/4167

23. "HTML Character Sets." W3Schools, http://w3school.se/charsets/default.html

24. Shannon, Ross. "The History of HTML | From the HTML 1.0 Spec to XHTML 1.0...." 21 Aug. 2012, https://www.yourhtmlsource.com/starthere/historyofhtml.html

25. "Internationalized Domain Names (IDN) FAQ." https://unicode.org/faq/idn.html

26. "Unicode Utilities: Confusables." http://unicode.org/cldr/utility/confusables.jsp?a=fast+forward+labs&r=None

27. "An Introduction to Multilingual Web Addresses." W3C, 9 May 2008, https://www.w3.org/International/articles/idn-and-iri/

28. American Civil Liberties Union v. Reno, 929 F. Supp. 824, 844 (E.D. Pa. 1996) (Dalzell, J.), https://law.justia.com/cases/federal/district-courts/FSupp/929/824/1812782/

29. "Usage of Content Languages for Websites." W3Techs, 28 Apr. 2019, https://w3techs.com/technologies/overview/content_language/all

30. "Ethnologue: Summary by World Area." https://www.ethnologue.com/statistics

31. "Managing Multi-Regional and Multilingual Sites." Google, https://support.google.com/webmasters/answer/182192?hl=en

32. “Unicode Security Considerations.” Unicode, http://www.unicode.org/reports/tr36/

33. “What Is Metcalfe's Law? - Definition from Techopedia.” Techopedia.com, https://www.techopedia.com/definition/29066/metcalfes-law
